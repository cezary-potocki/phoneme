{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyarabic.unshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import falconn\n",
    "import timeit\n",
    "from __future__ import print_function\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from configparser import ConfigParser\n",
    "import requests\n",
    "import pyphi\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_embedding_ws(name):\n",
    "    #url = 'http://54.36.53.127:8009/embedding'\n",
    "    url = 'http://127.0.0.1:8009/embedding'\n",
    "    headers = {\"content-type\": \"application/json;charset=utf-8\"}\n",
    "    response = requests.post(url, json=[name.upper()])\n",
    "    \n",
    "    arr = pyphi.jsonify.loads(response.text)\n",
    "    x = np.array(arr)\n",
    "    x = x.astype(dtype=np.float32)\n",
    "    return x[0]\n",
    "\n",
    "def reverse_name(name):\n",
    "    a=name.split()\n",
    "    a.reverse()\n",
    "    return \" \".join(a)\n",
    "\n",
    "def cos_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "    return dot_product\n",
    "\n",
    "def sort_by_distance(query_vector, result_vectors):\n",
    "    for v in result_vectors:\n",
    "        cos_similarity(query_vector, v)\n",
    "        \n",
    "        \n",
    "def query_lhs_table_by_distance(name, lhs_table, distance, names, vectors):\n",
    "    query = call_embedding_ws(name)\n",
    "    #query = eng_vectors_ee[0]\n",
    "    t1 = timeit.default_timer()\n",
    "    response = lhs_table.find_near_neighbors(query, distance)\n",
    "    \n",
    "    return process_lhs_table_response(query, response, names, vectors)\n",
    "    \n",
    "def query_lhs_table_by_number(name, lhs_table, number, names, vectors):\n",
    "    query = call_embedding_ws(name)\n",
    "    #query = eng_vectors_ee[0]\n",
    "    t1 = timeit.default_timer()\n",
    "    response = lhs_table.find_k_nearest_neighbors(query, k=number)\n",
    "    \n",
    "    return process_lhs_table_response(query, response, names, vectors)\n",
    "\n",
    "def query_lhs_table_nearest(name, lhs_table, names, vectors):\n",
    "    query = call_embedding_ws(name)\n",
    "    #query = eng_vectors_ee[0]\n",
    "    t1 = timeit.default_timer()\n",
    "    response = lhs_table.find_nearest_neighbor(query)\n",
    "    print(response)\n",
    "    return process_lhs_table_response(query, [response], names, vectors)\n",
    "\n",
    "def process_lhs_table_response(query, response, names, vectors):\n",
    "    df = pd.DataFrame(index=range(len(response)), columns=['id', 'name', 'cosine'])   \n",
    "    i = 0\n",
    "\n",
    "    for resp in response:\n",
    "        name = names.get_value(resp, 'name')\n",
    "        df.set_value(index=i, col='id', value=resp)\n",
    "        df.set_value(index=i, col='name', value=name)\n",
    "        df.set_value(index=i, col='cosine', value=cos_similarity(query, vectors[resp]))\n",
    "        i = i + 1\n",
    "     \n",
    "    df.sort_values('cosine', ascending=False)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #t2 = timeit.default_timer()    \n",
    "    #time = t2 - t1\n",
    "    return df\n",
    "\n",
    "\n",
    "def is_arabic(name):\n",
    "    res = re.findall(r'[\\u0600-\\u06FF]+',name)\n",
    "    if len(res) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#arab_names = pd.read_csv('/data/ARB_FULL_NAMES_VECTORS.csv', sep='|').reset_index(drop=True)\n",
    "#eng_names = pd.read_csv('/data/ENG_FULL_NAMES_VECTORS.csv', sep='|').reset_index(drop=True)\n",
    "eng_names = pd.read_csv('/data/ENG_TEST_NAME_VECTORS.csv', sep='|').reset_index(drop=True)\n",
    "\n",
    "#merged_names = arab_names.append(eng_names).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vector_strings = eng_names['vector'].as_matrix()\n",
    "eng_vectors = np.zeros(shape=(len(eng_vector_strings),256))\n",
    "i = 0\n",
    "for engv in eng_vector_strings:\n",
    "    x = np.fromstring(engv, dtype=np.float32, sep=',')\n",
    "    eng_vectors[i] = x\n",
    "    i = i+1\n",
    "eng_vectors = eng_vectors.astype(dtype=np.float32)\n",
    "eng_vector_strings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arab_vector_strings = arab_names['vector'].as_matrix()\n",
    "arab_vectors = np.zeros(shape=(len(arab_vector_strings),256))\n",
    "i = 0\n",
    "for arabv in arab_vector_strings:\n",
    "    x = np.fromstring(arabv, dtype=np.float32, sep=',')\n",
    "    arab_vectors[i] = x\n",
    "    i = i+1\n",
    "arab_vectors = arab_vectors.astype(dtype=np.float32)\n",
    "arab_vector_strings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "merged_vector_strings = merged_names['vector'].as_matrix()\n",
    "merged_vectors = np.zeros(shape=(len(merged_vector_strings),256))\n",
    "i = 0\n",
    "for mrgv in merged_vector_strings:\n",
    "    x = np.fromstring(mrgv, dtype=np.float32, sep=',')\n",
    "    merged_vectors[i] = x\n",
    "    i = i+1\n",
    "merged_vectors = merged_vectors.astype(dtype=np.float32)\n",
    "merged_vector_strings = None\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing the LSH table\n",
      "Done\n",
      "Construction time: 0.04594984196592122\n"
     ]
    }
   ],
   "source": [
    "number_of_tables = 50\n",
    "assert eng_vectors.dtype == np.float32\n",
    "\n",
    "params_cp = falconn.LSHConstructionParameters()\n",
    "params_cp.dimension = len(eng_vectors[0])\n",
    "params_cp.lsh_family = falconn.LSHFamily.CrossPolytope\n",
    "params_cp.distance_function = falconn.DistanceFunction.EuclideanSquared\n",
    "params_cp.l = number_of_tables\n",
    "# we set one rotation, since the data is dense enough,\n",
    "# for sparse data set it to 2\n",
    "params_cp.num_rotations = 2\n",
    "params_cp.seed = 5721840\n",
    "# we want to use all the available threads to set up\n",
    "params_cp.num_setup_threads = 0\n",
    "params_cp.storage_hash_table = falconn.StorageHashTable.BitPackedFlatHashTable\n",
    "# we build 24-bit hashes so that each table has\n",
    "# 2^24 bins; this is a good choise since 2^24 is of the same\n",
    "# order of magnitude as the number of data points\n",
    "falconn.compute_number_of_hash_functions(10, params_cp)\n",
    "\n",
    "print('Constructing the LSH table')\n",
    "t1 = timeit.default_timer()\n",
    "eng_table = falconn.LSHIndex(params_cp)\n",
    "eng_table.setup(eng_vectors)\n",
    "t2 = timeit.default_timer()\n",
    "print('Done')\n",
    "print('Construction time: {}'.format(t2 - t1))\n",
    "\n",
    "eng_query_object = eng_table.construct_query_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing the LSH table\n",
      "Done\n",
      "Construction time: 19.02402669400908\n"
     ]
    }
   ],
   "source": [
    "number_of_tables = 60\n",
    "assert arab_vectors.dtype == np.float32\n",
    "\n",
    "params_cp = falconn.LSHConstructionParameters()\n",
    "params_cp.dimension = len(arab_vectors[0])\n",
    "params_cp.lsh_family = falconn.LSHFamily.CrossPolytope\n",
    "params_cp.distance_function = falconn.DistanceFunction.NegativeInnerProduct\n",
    "params_cp.l = number_of_tables\n",
    "# we set one rotation, since the data is dense enough,\n",
    "# for sparse data set it to 2\n",
    "params_cp.num_rotations = 2\n",
    "params_cp.seed = 5721840\n",
    "# we want to use all the available threads to set up\n",
    "params_cp.num_setup_threads = 0\n",
    "params_cp.storage_hash_table = falconn.StorageHashTable.BitPackedFlatHashTable\n",
    "# we build 24-bit hashes so that each table has\n",
    "# 2^24 bins; this is a good choise since 2^24 is of the same\n",
    "# order of magnitude as the number of data points\n",
    "falconn.compute_number_of_hash_functions(16, params_cp)\n",
    "\n",
    "print('Constructing the LSH table')\n",
    "t1 = timeit.default_timer()\n",
    "arab_table = falconn.LSHIndex(params_cp)\n",
    "arab_table.setup(arab_vectors)\n",
    "t2 = timeit.default_timer()\n",
    "print('Done')\n",
    "print('Construction time: {}'.format(t2 - t1))\n",
    "\n",
    "arab_query_object = arab_table.construct_query_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "number_of_tables = 50\n",
    "assert merged_vectors.dtype == np.float32\n",
    "\n",
    "params_cp = falconn.LSHConstructionParameters()\n",
    "params_cp.dimension = len(merged_vectors[0])\n",
    "params_cp.lsh_family = falconn.LSHFamily.CrossPolytope\n",
    "params_cp.distance_function = falconn.DistanceFunction.EuclideanSquared\n",
    "params_cp.l = number_of_tables\n",
    "# we set one rotation, since the data is dense enough,\n",
    "# for sparse data set it to 2\n",
    "params_cp.num_rotations = 2\n",
    "params_cp.seed = 5721840\n",
    "# we want to use all the available threads to set up\n",
    "params_cp.num_setup_threads = 0\n",
    "params_cp.storage_hash_table = falconn.StorageHashTable.BitPackedFlatHashTable\n",
    "# we build 24-bit hashes so that each table has\n",
    "# 2^24 bins; this is a good choise since 2^24 is of the same\n",
    "# order of magnitude as the number of data points\n",
    "falconn.compute_number_of_hash_functions(20, params_cp)\n",
    "\n",
    "print('Constructing the LSH table')\n",
    "t1 = timeit.default_timer()\n",
    "merged_table = falconn.LSHIndex(params_cp)\n",
    "merged_table.setup(merged_vectors)\n",
    "t2 = timeit.default_timer()\n",
    "print('Done')\n",
    "print('Construction time: {}'.format(t2 - t1))\n",
    "\n",
    "merged_query_object = merged_table.construct_query_object()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET /near_neighbors\n",
    "\n",
    "req = json.loads(REQUEST)\n",
    "args = req['args']\n",
    "\n",
    "if 'name' not in args:\n",
    "    print(json.dumps({'nearNeighbors': None}))\n",
    "else:\n",
    "    name = args['name'][0]\n",
    "    if 'distance' not in args:\n",
    "        distance = 1\n",
    "    else:\n",
    "        distance = float(args['distance'][0])\n",
    "    \n",
    "    eng_df = query_lhs_table_by_distance(\n",
    "        name=name, \n",
    "        lhs_table=eng_query_object, \n",
    "        distance=distance, \n",
    "        names=eng_names, \n",
    "        vectors=eng_vectors)\n",
    "    \n",
    "    eng_df_reversed = query_lhs_table_by_distance(\n",
    "        name=reverse_name(name), \n",
    "        lhs_table=eng_query_object, \n",
    "        distance=distance, \n",
    "        names=eng_names,  \n",
    "        vectors=eng_vectors)\n",
    "    \n",
    "    \n",
    "    arb_df = query_lhs_table_by_distance(\n",
    "        name=name, \n",
    "        lhs_table=arab_query_object, \n",
    "        distance=distance, \n",
    "        names=arab_names,  \n",
    "        vectors=arab_vectors)\n",
    "    \n",
    "    arb_df_reversed = query_lhs_table_by_distance(\n",
    "        name=reverse_name(name), \n",
    "        lhs_table=arab_query_object, \n",
    "        distance=distance, \n",
    "        names=arab_names,  \n",
    "        vectors=arab_vectors)\n",
    "    \n",
    "    eng_df_merged = eng_df.append(eng_df_reversed).drop_duplicates(['name'], keep='last')    \n",
    "    eng_df_merged = eng_df_merged.sort_values('cosine', ascending=False)\n",
    "    eng_json = eng_df_merged.to_json(orient='records')[1:-1]\n",
    "    \n",
    "    arb_df_merged = arb_df.append(arb_df_reversed).drop_duplicates(['name'], keep='last')    \n",
    "    arb_df_merged = arb_df_merged.sort_values('cosine', ascending=False)\n",
    "    arb_json = arb_df_merged.to_json(orient='records')[1:-1]\n",
    "    \n",
    "    print('{\\\"english\\\":[' + eng_json + '], \\\"arabic\\\":[' + arb_json + ']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET /near_n_neighbors\n",
    "\n",
    "req = json.loads(REQUEST)\n",
    "args = req['args']\n",
    "\n",
    "if 'name' not in args:\n",
    "     print('{\\\"english\\\":[], \\\"arabic\\\":[]}')\n",
    "else:\n",
    "    name = args['name'][0]\n",
    "    if 'num' not in args:\n",
    "        number = 1\n",
    "    else:\n",
    "        number = int(args['num'][0])\n",
    "    \n",
    "    eng_df = query_lhs_table_by_number(\n",
    "        name=name, \n",
    "        lhs_table=eng_query_object, \n",
    "        num=number, \n",
    "        names=eng_names, \n",
    "        vectors=eng_vectors)\n",
    "    \n",
    "    eng_df_reversed = query_lhs_table_by_number(\n",
    "        name=reverse_name(name), \n",
    "        lhs_table=eng_query_object, \n",
    "        num=number, \n",
    "        names=eng_names,  \n",
    "        vectors=eng_vectors)\n",
    "    \n",
    "    \n",
    "    arb_df = query_lhs_table_by_number(\n",
    "        name=name, \n",
    "        lhs_table=arab_query_object, \n",
    "        num=number,  \n",
    "        names=arab_names,  \n",
    "        vectors=arab_vectors)\n",
    "    \n",
    "    arb_df_reversed = query_lhs_table_by_number(\n",
    "        name=reverse_name(name), \n",
    "        lhs_table=arab_query_object, \n",
    "        num=number, \n",
    "        names=arab_names,  \n",
    "        vectors=arab_vectors)\n",
    "    \n",
    "    eng_df_merged = eng_df.append(eng_df_reversed).drop_duplicates(['name'], keep='last')    \n",
    "    eng_df_merged = eng_df_merged.sort_values('cosine', ascending=False)\n",
    "    eng_json = eng_df_merged.to_json(orient='records')[1:-1]\n",
    "    \n",
    "    arb_df_merged = arb_df.append(arb_df_reversed).drop_duplicates(['name'], keep='last')    \n",
    "    arb_df_merged = arb_df_merged.sort_values('cosine', ascending=False)\n",
    "    arb_json = arb_df_merged.to_json(orient='records')[1:-1]\n",
    "    \n",
    "    print('{\\\"english\\\":[' + eng_json + '], \\\"arabic\\\":[' + arb_json + ']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "    return dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id             name cosine\n",
      "0   25    ASEEL TRINITY      1\n",
      "1   26    ASEIL TRINITY      1\n",
      "2    3     MARAM ASALAH      1\n",
      "3    0      MARAM NAOMI      1\n",
      "4    2      MARAM ASALA      1\n",
      "5    6       MURAD ELLA      1\n",
      "6    7       MORAD ELLA      1\n",
      "7    8     MURAD MONEER      1\n",
      "8    4   MURAD SERENITY      1\n",
      "9    1  MARAM ANNABELLA      1\n",
      "10   5   MORAD SERENITY      1\n",
      "11  28    ASALA TASNEEM      1\n",
      "12  13      MURAD MONIR      1\n",
      "13  14     MURAD MUNEER      1\n",
      "14  15      MURAD MUNIR      1\n",
      "15  16   ASEEL JONATHAN      1\n",
      "16  17   ASEEL JONATHON      1\n",
      "17  18   ASEIL JONATHAN      1\n",
      "18  19   ASEIL JONATHON      1\n",
      "19   9     MORAD MONEER      1\n",
      "20  10      MORAD MONIR      1\n",
      "21  22  ASEEL SEBASTIAN      1\n",
      "22  23  ASEIL SEBASTIAN      1\n",
      "23  11     MORAD MUNEER      1\n",
      "24  12      MORAD MUNIR      1\n"
     ]
    }
   ],
   "source": [
    "name='MARAM ANNABELLA'\n",
    "\n",
    "eng_df = query_lhs_table_by_number(\n",
    "        name=name, \n",
    "        lhs_table=eng_query_object, \n",
    "        number=25, \n",
    "        names=eng_names, \n",
    "        vectors=eng_vectors)\n",
    "\n",
    "print(eng_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.2 ms, sys: 2.22 ms, total: 52.4 ms\n",
      "Wall time: 65.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#name='ABDAL RAHEEM'\n",
    "name='MARAM ANNABELLA'\n",
    "name_vector = call_embedding_ws(name)\n",
    "distances = pd.DataFrame(index=range(len(eng_vectors)),columns=['name', 'cosine'])\n",
    "distances.loc[eng_names.index,['name']] = eng_names[['name']]\n",
    "\n",
    "for i in range(len(eng_vectors)):\n",
    "    distances.set_value(col='cosine', index=i, value=cos_similarity(name_vector, eng_vectors[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 name    cosine\n",
      "0         MARAM NAOMI         1\n",
      "26      ASEIL TRINITY         1\n",
      "281    RAKAN IZABELLE         1\n",
      "33       ASALA MANAAR         1\n",
      "32        ASALA MANAR         1\n",
      "284       RAZAN RAKAN         1\n",
      "285      RAZAN RAAKAN         1\n",
      "278    RAKAN ISABELLA         1\n",
      "29       ASALA TASNIM         1\n",
      "28      ASALA TASNEEM         1\n",
      "286      RAZAN NASEEM         1\n",
      "46        MARIA MURAD         1\n",
      "47        MARIA MORAD         1\n",
      "275      RAKAN MAASON         1\n",
      "539       MASON MARAM         1\n",
      "274       RAKAN MASON         1\n",
      "25      ASEEL TRINITY         1\n",
      "37      ASALA MIKHAEL         1\n",
      "287       RAZAN NASIM         1\n",
      "23    ASEIL SEBASTIAN         1\n",
      "22    ASEEL SEBASTIAN         1\n",
      "288       RAZAN NSEEM         1\n",
      "289      RAZAN JOSHUA         1\n",
      "19     ASEIL JONATHON         1\n",
      "18     ASEIL JONATHAN         1\n",
      "55         MARIA SUAD         1\n",
      "254    KALID JONATHON         1\n",
      "407      ISAAK NASEEM         1\n",
      "75      NASIM MUNEERA         1\n",
      "201       SOAAD MARAM         1\n",
      "..                ...       ...\n",
      "413    ISAAK SERENITY         1\n",
      "394      ILIJA SAMUEL         1\n",
      "414    ISSAC SERENITY         1\n",
      "136      MUNIR JAMEEL         1\n",
      "137       MUNIR JAMIL         1\n",
      "384      NAOMI AMIRAH         1\n",
      "139   MONIR SEBASTIAN         1\n",
      "392    ILIJA ALEXANDR         1\n",
      "391  ILIJA ALEKSANDAR         1\n",
      "396      ILIJA NEVAEH         1\n",
      "403       ISAAK RAKAN         1\n",
      "404      ISAAK RAAKAN         1\n",
      "405       ISSAC RAKAN         1\n",
      "1     MARAM ANNABELLA         1\n",
      "53       MARIAH SUAAD  0.998865\n",
      "44       MARIAH MURAD  0.998865\n",
      "45       MARIAH MORAD  0.998865\n",
      "540      MAASON MARAM  0.998865\n",
      "50        MARIAH SUAD  0.998865\n",
      "51        MARIAH SOAD  0.998865\n",
      "537       MAASON RAAD  0.998865\n",
      "464    SAMUEL MUNIRAH  0.998865\n",
      "54       MARIAH SOAAD  0.998865\n",
      "533      MAASON JAMIL  0.998865\n",
      "532     MAASON JAMEEL  0.998865\n",
      "111    JAMILA TRINITY  0.998865\n",
      "497      MIKAEL ISSAC  0.998865\n",
      "487       MIKAEL SOAD  0.998865\n",
      "43      ASALAH MIKAEL  0.998865\n",
      "65      MARIAH KHALID  0.998865\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "distances = distances.sort_values('cosine', ascending=False)\n",
    "print(distances.head(150)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name2 = 'DIERA MIRZAKHODZHAEVA'\n",
    "name2_vector = call_embedding_ws(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarity(name_vector, name2_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(name_vector)):\n",
    "    print(name_vector[i]==name2_vector[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = call_embedding_ws('ASALA TASNIM')\n",
    "v2 = call_embedding_ws('MARIA MORAD')\n",
    "cos_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for idx, val in enumerate(v1):\n",
    "    print(v1[idx] == v2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
