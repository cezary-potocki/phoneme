{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from configparser import ConfigParser\n",
    "import networkx as nx\n",
    "\n",
    "def config(filename='prepare_data.ini', section='phonetic'):\n",
    "    parser = ConfigParser()\n",
    "    parser.read(filename)\n",
    " \n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    " \n",
    "    return db\n",
    "\n",
    "def db_connect():\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    params = config()\n",
    "    conn = psycopg2.connect(**params)\n",
    "    print('Connected to the PostgreSQL database...')\n",
    "    \n",
    "    return conn\n",
    "\n",
    "def read_dataframe(query):\n",
    "    conn = db_connect()\n",
    "    result = None\n",
    "    try:\n",
    "        result = pd.read_sql(query, con=conn, index_col='id')\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_graph(query, pickle_file):\n",
    "    df = read_dataframe(query)\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        arb, eng, cnt = row['arb'], row['eng'], row['cnt']\n",
    "        if G.has_edge(arb, eng):\n",
    "            G[arb][eng]['weight'] += cnt\n",
    "        else:\n",
    "            G.add_edge(arb, eng, weight=cnt)\n",
    "    nx.write_gpickle(G,pickle_file)\n",
    "\n",
    "def generate_given_names_graph():\n",
    "    query = \"\"\"\n",
    "            SELECT ID, ARB, ENG, COUNT AS CNT FROM GIVEN_NAMES_MASTER\n",
    "            WHERE ARB IS NOT NULL AND ENG IS NOT NULL AND ARB != '' AND ENG != ''\n",
    "            \"\"\"\n",
    "    generate_graph(query, \"/home/jupyter/notebooks/PoC/data-preparation/pickle/given_names_graph.gpickle\")\n",
    "\n",
    "def generate_family_names_graph():\n",
    "    query = \"\"\"\n",
    "            SELECT ID, ARB, ENG, COUNT AS CNT FROM FAMILY_NAMES_MASTER\n",
    "            WHERE ARB IS NOT NULL AND ENG IS NOT NULL AND ARB != '' AND ENG != ''\n",
    "            \"\"\"\n",
    "    generate_graph(query, \"/home/jupyter/notebooks/PoC/data-preparation/pickle/family_names_graph.gpickle\")\n",
    "\n",
    "def generate_dan_names_graph():\n",
    "    query = \"\"\"\n",
    "            SELECT ID, ARB, ENG, FREQ AS CNT FROM GIVEN_NAMES_DAN\n",
    "            WHERE ARB IS NOT NULL AND ENG IS NOT NULL AND ARB != '' AND ENG != ''\n",
    "            \"\"\"\n",
    "    generate_graph(query,\"/home/jupyter/notebooks/PoC/data-preparation/pickle/dan_names_graph.gpickle\")\n",
    "\n",
    "def read_given_names_graph():\n",
    "    return nx.read_gpickle(\"/home/jupyter/notebooks/PoC/data-preparation/pickle/given_names_graph.gpickle\")\n",
    "    \n",
    "def read_family_names_graph():\n",
    "    return nx.read_gpickle(\"/home/jupyter/notebooks/PoC/data-preparation/pickle/family_names_graph.gpickle\")\n",
    "    \n",
    "def read_dan_names_graph():\n",
    "    return nx.read_gpickle(\"/home/jupyter/notebooks/PoC/data-preparation/pickle/dan_names_graph.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "top_noise_alike_data = [\n",
    "    'XXX', 'UNKNOWN',  'WITHOUT', 'MADAM'\n",
    "'متوفر','منزل', ''\n",
    "'عير مبين', 'عيرمعروف' ,'عير معروف', 'عير معروفه',  'غبر معروف', \n",
    "'غرر معروف', 'غيتتتر مبيتتتن', 'غيتتتر مبيتتن', 'غيتتر مبيتتتن', 'غيتتر مبيتتن', 'غيتر مبتتين', 'غيتر مبين', \n",
    "'غيتر معروف', 'غير توفر', 'غيرر معروف', 'غير مبن', 'غير مبيتتتتن', 'غير مبيتتن', \n",
    "\n",
    "\n",
    "'غير مححد', 'غيرمحد', \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'غير موجو', \n",
    "'غير نعروف', \n",
    "'غير وعروف', 'غيلر معروف', \n",
    "    \n",
    "    'السيد', \n",
    "    'لايوجد', 'لا يوجد', \n",
    "    'غير معروف', 'غيرمعروف',\n",
    "    'غير معرف',  'غيرمعرف',\n",
    "    'غيرموجود', 'غير موجود',\n",
    "    'غير متوفر', 'غيرمتوفر', \n",
    "    'غير محدد', 'غيرمحدد', \n",
    "    'غير مبين', 'غيرمبين', \n",
    "    'غير معلوم', 'غيرمعلوم',\n",
    "    'غير مذكور', 'غيرمذكور', \n",
    "    'غير معترف', 'غيرمعترف', \n",
    "    'غير معترف', 'غيرمعترف', \n",
    "    'عير مغروف', 'عيرمغروف', \n",
    "    'غير مغروف', 'غيرمغروف', \n",
    "]\n",
    "\n",
    "top_noise_data = [\n",
    "    'MRS', 'MRS.', 'MRSS', 'MR', 'MR.', 'MISS', 'MIS', 'AL-SAYYDA', 'SAYEDA', 'SHE', 'N A'\n",
    "    'الله', 'غير'\n",
    "]\n",
    "\n",
    "given_limit = 10\n",
    "family_limit = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_variants(names, graphs, validate = False):\n",
    "    iterable_list = names[:]\n",
    "    total_variants = []\n",
    "    for name in iterable_list:\n",
    "        #print(\"processing name: {name}\".format(name=name))\n",
    "        variants = get_variants(name, graphs)\n",
    "        total_variants += get_top_frequency_names(variants)\n",
    "    total_variants = list(set(total_variants))\n",
    "    #print(\"total_variants: {total_variants}\".format(total_variants=total_variants))\n",
    "    if validate:\n",
    "        iterable_list = total_variants[:]\n",
    "        for name in iterable_list:\n",
    "            if not validate_name_by_variants(name, graphs, names):\n",
    "                #print(\"removing name: {name}\".format(name=name))\n",
    "                total_variants.remove(name)\n",
    "        total_variants\n",
    "        \n",
    "    return total_variants\n",
    "                \n",
    "\n",
    "def get_variants(name, graphs=['given']):\n",
    "    result = {}\n",
    "    for gr in graphs:\n",
    "        for v,u in nx.edges(G[gr], name):\n",
    "            freq = G[gr][v][u]['weight']\n",
    "            if not u in result:\n",
    "                result[u] = freq\n",
    "            else:\n",
    "                result[u] += freq\n",
    "    return result\n",
    "\n",
    "def validate_name_by_variants(name, graphs, valid_variants):\n",
    "    variants = get_variants(name, graphs)\n",
    "    total_valid_count = 0\n",
    "    total_invalid_count = 0\n",
    "    \n",
    "    total = sum(variants.values())\n",
    "    if total < 3:\n",
    "        return False\n",
    "\n",
    "    for key, val in variants.items():\n",
    "        if key in valid_variants:\n",
    "            total_valid_count += val\n",
    "        else:\n",
    "            total_invalid_count += val\n",
    "    \n",
    "    #print(\"for {name}: valid: {valid}, invalid: {invalid}\".format(name=name, valid=total_valid_count, invalid=total_invalid_count))\n",
    "    \n",
    "    if total_valid_count < 3:\n",
    "        return False\n",
    "\n",
    "    if total_valid_count > total_invalid_count or total_valid_count > 100:\n",
    "        return True\n",
    "    \n",
    "    #print(\"variations for {name} are: {dic}\".format(name=name, dic=variants))\n",
    "    return False\n",
    "    \n",
    "\n",
    "def get_top_frequency_names(list):\n",
    "    total = sum(list.values())\n",
    "    lower_accepted_frequency = 100\n",
    "    threshold = 10\n",
    "    \n",
    "    max_value = max(list.values())\n",
    "    if total > 6561:\n",
    "        threshold = 1\n",
    "    else:\n",
    "        threshold -= total**(1./4.)\n",
    "        \n",
    "    #print(\"threshold: {thre}, total: {tot}\".format(thre=threshold, tot=total))\n",
    "    matched_list = [key for key, val in list.items() \n",
    "                    if len(key) > 2 and \n",
    "                    key not in top_noise_data and \n",
    "                    not any(x in key for x in top_noise_alike_data) and\n",
    "                    (val / total * 100 > threshold or val >= lower_accepted_frequency)]\n",
    "    #print(\"top matched_list: {thre}\".format(thre=matched_list))\n",
    "    not_matched_list = [ (key, val) for key, val in list.items() if val / total * 100 <= threshold and val < lower_accepted_frequency]\n",
    "    matched_list_with_composite = [key for key, val in list.items() \n",
    "                                   if any(match in key and len(key) < len(match) * 2  for match in matched_list)]\n",
    "    if(len(matched_list_with_composite) - len(matched_list) > 3):\n",
    "        return matched_list\n",
    "    \n",
    "    return matched_list_with_composite\n",
    "\n",
    "def process_name_pair(english_name, arabic_name, graphs):\n",
    "    arabic_variants = build_variants([english_name], graphs)\n",
    "    english_variants = build_variants([arabic_name], graphs)\n",
    "    #print(\"first iteration results, arabic: {arb}, english: {eng}\".format(arb=arabic_variants, eng=english_variants))\n",
    "    arabic_variants += build_variants(english_variants, graphs, True)\n",
    "    arabic_variants = list(set(arabic_variants))\n",
    "    if arabic_name not in arabic_variants:\n",
    "        arabic_variants.append(arabic_name)\n",
    "    english_variants += build_variants(arabic_variants, graphs, True)\n",
    "    english_variants = list(set(english_variants))\n",
    "    if english_name not in english_variants:\n",
    "        english_variants.append(english_name)\n",
    "    #print(\"second iteration results, arabic: {arb}, english: {eng}\".format(arb=arabic_variants, eng=english_variants))\n",
    "    return english_variants, arabic_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate_given_names_graph()\n",
    "#generate_family_names_graph()\n",
    "#generate_dan_names_graph()\n",
    "\n",
    "G = {}\n",
    "G['given'] = read_given_names_graph()\n",
    "G['family'] =  read_family_names_graph()\n",
    "G['dan'] = read_dan_names_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the PostgreSQL database...\n",
      "given limit: 10\n",
      "Connected to the PostgreSQL database...\n",
      "family limit: 10\n"
     ]
    }
   ],
   "source": [
    "def read_top_given_names():\n",
    "    conn = db_connect()\n",
    "    print(\"given limit: {gl}\".format(gl=given_limit))\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT * FROM (\n",
    "                SELECT ENG, ARB, SUM(COUNT) AS S FROM (\n",
    "                    SELECT ENG, ARB, COUNT FROM GIVEN_NAMES_MASTER\n",
    "                    WHERE ENG IS NOT NULL AND ENG != '' AND ARB IS NOT NULL AND ARB != ''\n",
    "                ) AS SUB GROUP BY ENG, ARB\n",
    "                ORDER BY S DESC\n",
    "            ) AS S LIMIT {gl}\n",
    "            \"\"\".format(gl=given_limit)\n",
    "        sql_result = pd.read_sql(query, con=conn)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "    return [[x[1], x[2]] for x in sql_result[['eng','arb']].itertuples()]   \n",
    "\n",
    "top_given_names = read_top_given_names()\n",
    "\n",
    "def read_top_family_names():\n",
    "    conn = db_connect()\n",
    "    print(\"family limit: {fl}\".format(fl=family_limit))\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT * FROM (\n",
    "                SELECT ENG, ARB, SUM(COUNT) AS S FROM (\n",
    "                    SELECT ENG, ARB, COUNT FROM FAMILY_NAMES_MASTER\n",
    "                    WHERE ENG IS NOT NULL AND ENG != '' AND ARB IS NOT NULL AND ARB != ''\n",
    "                ) AS SUB GROUP BY ENG, ARB\n",
    "                ORDER BY S DESC\n",
    "            ) AS S2 LIMIT {fl}\n",
    "            \"\"\".format(fl=family_limit)\n",
    "        sql_result = pd.read_sql(query, con=conn)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "    return [[x[1], x[2]] for x in sql_result[['eng','arb']].itertuples()]   \n",
    "\n",
    "'''top_family_names = \n",
    "    [\n",
    "        ['ALI','علي'],\n",
    "        ['KHAN','خان'],\n",
    "        ['SALEH','صالح'],\n",
    "        ['SHAH','شاه'],\n",
    "        ['HUSSEIN','حسين'],\n",
    "        ['ABBAS','عباس'],\n",
    "        ['RAHMAN','رحمن'],\n",
    "        ['HUSSAIN','حسين'],\n",
    "        ['OSMAN','عصمان'],\n",
    "        ['KHALIL','خليل'],\n",
    "        ['THOMAS','توماس'],\n",
    "        ['SAAD','سعد'],\n",
    "        ['AZIZ','عزيز'],\n",
    "        ['KAMAL','كمال'],\n",
    "        ['SULTAN','سلطان'],\n",
    "        ['HAMED','حامد'],\n",
    "        ['SILVA','سيلفا'],\n",
    "        ['BUTT','بت'],\n",
    "        ['SMITH','سميث'],\n",
    "        ['ALEXANDER','الكسندر']]'''\n",
    "top_family_names = read_top_family_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "from fuzzywuzzy import fuzz\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def prepare_given_names(dir_prefix):\n",
    "    given_names = []\n",
    "    \n",
    "    outer_index = 0\n",
    "    for pair in top_given_names:\n",
    "        outer_index += 1\n",
    "        if outer_index % 10000 == 0:\n",
    "            print(\"processing the given names, batch {index}\".format(index=(outer_index / 10000)))\n",
    "\n",
    "        given_names.append(process_name_pair(pair[0], pair[1],['dan', 'given']))\n",
    "    prepare_names(given_names, dir_prefix)\n",
    "\n",
    "def prepare_family_names(dir_prefix):\n",
    "    family_names = []\n",
    "    \n",
    "    outer_index = 0\n",
    "    for pair in top_family_names:\n",
    "        outer_index += 1\n",
    "        if outer_index % 10000 == 0:\n",
    "            print(\"processing the family names, batch {index}\".format(index=(outer_index / 10000)))\n",
    "\n",
    "        family_names.append(process_name_pair(pair[0], pair[1],['family']))\n",
    "    prepare_names(family_names, dir_prefix)\n",
    "\n",
    "\n",
    "def prepare_names(all_names, file_prefix):\n",
    "    \n",
    "    eng_ara_pairs = open(file_prefix + \"eng_ara_pairs.csv\", 'w')\n",
    "    eng_eng_pairs = open(file_prefix + \"eng_eng_pairs.csv\", 'w')\n",
    "    ara_ara_pairs = open(file_prefix + \"ara_ara_pairs.csv\", 'w')\n",
    "    negative_pairs = open(file_prefix + \"negative_pairs.csv\", 'w')\n",
    "    eng_eng_nagative_pairs = open(file_prefix + \"eng_eng_nagative_pairs.csv\", 'w')\n",
    "    ara_ara_negative_pairs = open(file_prefix + \"ara_ara_negative_pairs.csv\", 'w')\n",
    "    \n",
    "    fuzzy_distance = 50\n",
    "    \n",
    "    l = len(all_names)\n",
    "    for index, gn in enumerate(all_names):\n",
    "        if index % 10000 == 0:\n",
    "            print(\"preparing name lists, batch {index}\".format(index=(index / 10000)))\n",
    "\n",
    "        eng_eng = list(itertools.combinations(gn[0], 2))\n",
    "        eng_eng = [list(elem) for elem in eng_eng]\n",
    "        #print(len(eng_eng))\n",
    "        for item in eng_eng:\n",
    "            item[0].strip()\n",
    "            item[1].strip()\n",
    "            eng_eng_pairs.write(\"{a}|{b}\\n\".format(a=item[0], b=item[1]))\n",
    "        \n",
    "        ara_ara = list(itertools.combinations(gn[1], 2))\n",
    "        ara_ara = [list(elem) for elem in ara_ara]\n",
    "        #print(len(ara_ara))\n",
    "        for item in ara_ara:\n",
    "            item[0].strip()\n",
    "            item[1].strip()\n",
    "            ara_ara_pairs.write(\"{a}|{b}\\n\".format(a=item[0], b=item[1]))\n",
    "        \n",
    "        ##generate negative labels\n",
    "        r = list(range(0,index)) + list(range(index+1, l))\n",
    "        eng_ara_unmatched_random_names = []\n",
    "        eng_eng_unmatched_random_names = []\n",
    "        ara_ara_unmatched_random_names = []\n",
    "        \n",
    "        for b in range(0, len(gn[0])):\n",
    "            for c in range(0, len(gn[0]) - 1):\n",
    "                eng_eng_unmatched_random_names.append(random.choice(r))\n",
    "            for c in range(0, len(gn[1]) - 1):\n",
    "                eng_ara_unmatched_random_names.append(random.choice(r))\n",
    "            \n",
    "        for b in range(0, len(gn[1])):\n",
    "            for c in range(0, len(gn[0]) - 1):\n",
    "                eng_eng_unmatched_random_names.append(random.choice(r))\n",
    "            for c in range(0, len(gn[1]) - 1):\n",
    "                ara_ara_unmatched_random_names.append(random.choice(r))\n",
    "        \n",
    "        #print(len(eng_eng_unmatched_random_names))\n",
    "        #print(len(ara_ara_unmatched_random_names))\n",
    "        #print(\"range={r}, index = {index}, current_list={gn}, e={e}, a={a}\".format(r=r, index=index, gn=gn, e=english_unmatched_random_names,a=arabic_unmatched_random_names ))\n",
    "        \n",
    "        for arb in gn[1]:\n",
    "            arb.strip()\n",
    "            #count = 0\n",
    "            for c in range(0, len(gn[0]) - 1):\n",
    "                r = eng_eng_unmatched_random_names.pop()\n",
    "                negative__idx = np.random.randint(low=0, high=len(all_names[r][0]))\n",
    "                random_value = all_names[r][0][negative__idx]\n",
    "                compare_value = all_names[r][1][0]\n",
    "                if fuzz.partial_ratio(compare_value, arb) < fuzzy_distance:\n",
    "                    random_value.strip()\n",
    "                    negative_pairs.write(\"{r}|{a}\\n\".format(a=arb,r=random_value))\n",
    "                    #count = count + 1\n",
    "                    #print(\"added name: {name}, negative: {ne}\".format(name=arb, ne=random_value))\n",
    "                #else:\n",
    "                    #print(\"not added name: {name}, negative: {ne}, comapred value: {cv}\".format(name=arb, ne=random_value, cv=compare_value))\n",
    "            #print(count)\n",
    "            #count = 0\n",
    "            for c in range(0, len(gn[1]) - 1):\n",
    "                r = ara_ara_unmatched_random_names.pop()\n",
    "                negative__idx = np.random.randint(low=0, high=len(all_names[r][1]))\n",
    "                random_value = all_names[r][1][negative__idx]\n",
    "                if fuzz.partial_ratio(random_value, arb) < fuzzy_distance:\n",
    "                    random_value.strip()\n",
    "                    ara_ara_negative_pairs.write(\"{a}|{r}\\n\".format(a=arb,r=random_value))\n",
    "                    #count = count + 1\n",
    "                    #print(\"added name: {name}, negative: {ne}\".format(name=arb, ne=random_value))\n",
    "                #else:\n",
    "                    #print(\"not added name: {name}, negative: {ne}\".format(name=arb, ne=random_value))\n",
    "            #print(count)\n",
    "        for eng in gn[0]:\n",
    "            eng.strip()\n",
    "            #count = 0\n",
    "            for c in range(0, len(gn[0]) - 1):\n",
    "                r = eng_eng_unmatched_random_names.pop()\n",
    "                negative__idx = np.random.randint(low=0, high=len(all_names[r][0]))\n",
    "                random_value = all_names[r][0][negative__idx]\n",
    "                if fuzz.partial_ratio(random_value, eng) < fuzzy_distance:\n",
    "                    random_value.strip()\n",
    "                    eng_eng_nagative_pairs.write(\"{e}|{r}\\n\".format(e=eng,r=random_value))\n",
    "                    #count = count + 1\n",
    "                    #print(\"added name: {name}, negative: {ne}\".format(name=eng, ne=random_value))\n",
    "                #else:\n",
    "                    #print(\"not added name: {name}, negative: {ne}\".format(name=eng, ne=random_value))\n",
    "            #print(count)\n",
    "            #count = 0\n",
    "            for c in range(0, len(gn[1]) - 1):\n",
    "                r = eng_ara_unmatched_random_names.pop()\n",
    "                negative__idx = np.random.randint(low=0, high=len(all_names[r][1]))\n",
    "                random_value = all_names[r][1][negative__idx]\n",
    "                compare_value = all_names[r][0][0]\n",
    "\n",
    "                if fuzz.partial_ratio(compare_value, eng) < fuzzy_distance:\n",
    "                    random_value.strip()\n",
    "                    negative_pairs.write(\"{e}|{r}\\n\".format(e=eng,r=random_value))\n",
    "                    #count = count + 1\n",
    "                    #print(\"added name: {name}, negative: {ne}\".format(name=eng, ne=random_value))\n",
    "                #else:\n",
    "                    #print(\"not added name: {name}, negative: {ne}, comapred value: {cv}\".format(name=eng, ne=random_value, cv=compare_value))\n",
    "            #print(count)\n",
    "            \n",
    "            for arb in gn[1]:\n",
    "                arb.strip()\n",
    "                eng_ara_pairs.write(\"{e}|{a}\\n\".format(e=eng,a=arb))\n",
    "                \n",
    "    eng_ara_pairs.close()\n",
    "    eng_eng_pairs.close()\n",
    "    ara_ara_pairs.close()\n",
    "    negative_pairs.close()\n",
    "    eng_eng_nagative_pairs.close()\n",
    "    ara_ara_negative_pairs.close()\n",
    "\n",
    "\n",
    "def generate_full_names(file_name):\n",
    "    \n",
    "    target_dir = \"/home/jupyter/notebooks/PoC/data-preparation/name-pairs/{gl}_{fl}/\".format(gl=given_limit, fl=family_limit)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    \n",
    "    prepare_given_names(target_dir + \"given_\")\n",
    "    prepare_family_names(target_dir + \"family_\")\n",
    "\n",
    "    \n",
    "    with open(target_dir + '/given_eng_ara_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        given_names = list(reader)\n",
    "    f.close()\n",
    "    \n",
    "    with open(target_dir + '/given_ara_ara_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        ara_ara_pairs = list(reader)\n",
    "    f.close()\n",
    "        \n",
    "    with open(target_dir + '/given_eng_eng_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        eng_eng_pairs = list(reader)\n",
    "    f.close()    \n",
    "    \n",
    "    with open(target_dir + '/given_negative_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        negative_pairs = list(reader)\n",
    "    f.close()    \n",
    "        \n",
    "    with open(target_dir + '/given_eng_eng_nagative_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        eng_eng_nagative_pairs = list(reader)\n",
    "    f.close()\n",
    "    \n",
    "    with open(target_dir + '/given_ara_ara_negative_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        ara_ara_negative_pairs = list(reader)\n",
    "    f.close()    \n",
    "        \n",
    "    with open(target_dir + '/family_eng_ara_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        family_names = list(reader)\n",
    "    f.close()\n",
    "    \n",
    "    with open(target_dir + '/family_eng_eng_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        family_eng_eng_pairs = list(reader)\n",
    "    f.close()\n",
    "    \n",
    "    with open(target_dir + '/family_ara_ara_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        family_ara_ara_pairs = list(reader)\n",
    "    f.close()    \n",
    "        \n",
    "    with open(target_dir + '/family_negative_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        family_negative_pairs = list(reader)\n",
    "    f.close()\n",
    "    \n",
    "    with open(target_dir + '/family_eng_eng_nagative_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        family_eng_eng_nagative_pairs = list(reader)\n",
    "    f.close()\n",
    "    \n",
    "    with open(target_dir + '/family_ara_ara_negative_pairs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter ='|')\n",
    "        family_ara_ara_negative_pairs = list(reader)\n",
    "    f.close()\n",
    "         \n",
    "    '''\n",
    "    print(len(given_names))\n",
    "    print(len(eng_eng_pairs))\n",
    "    print(len(ara_ara_pairs))\n",
    "    print(len(negative_pairs))\n",
    "    print(len(eng_eng_nagative_pairs))\n",
    "    print(len(ara_ara_negative_pairs))\n",
    "    print(len(family_names))\n",
    "    print(len(family_eng_eng_pairs))\n",
    "    print(len(family_ara_ara_pairs))\n",
    "    print(len(family_negative_pairs))\n",
    "    print(len(family_eng_eng_nagative_pairs))\n",
    "    print(len(family_ara_ara_negative_pairs))\n",
    "    \n",
    "    \n",
    "    print(given_names)\n",
    "    print(eng_eng_pairs)\n",
    "    print(ara_ara_pairs)\n",
    "    print(negative_pairs)\n",
    "    print(eng_eng_nagative_pairs)\n",
    "    print(ara_ara_negative_pairs)\n",
    "    print(family_names)\n",
    "    print(family_eng_eng_pairs)\n",
    "    print(family_ara_ara_pairs)\n",
    "    print(family_negative_pairs)\n",
    "    print(family_eng_eng_nagative_pairs)\n",
    "    print(family_ara_ara_negative_pairs)\n",
    "    '''\n",
    "    \n",
    "    f = open(\"/home/jupyter/notebooks/PoC/data-preparation/full-names/{f}\".format(f=file_name),'w')\n",
    "    \n",
    "    given_names_range = list(range(len(given_names)))\n",
    "    family_names_range = list(range(len(family_names)))\n",
    "    negative_given_names_range = list(range(len(negative_pairs)))\n",
    "    negative_family_names_range = list(range(len(family_negative_pairs)))\n",
    "    \n",
    "    outer_index = 0\n",
    "    while True:\n",
    "        gn_pairs = []\n",
    "        outer_index += 1\n",
    "        if outer_index % 10000 == 0:\n",
    "            print(\"generating full names, batch {index}\".format(index=(outer_index / 10000)))\n",
    "\n",
    "        for i in range(3):\n",
    "            gn_idx = 0\n",
    "            if len(given_names_range) > 0:\n",
    "                gn_idx = np.random.randint(low=0, high=len(given_names_range))\n",
    "                gn_pair = given_names[given_names_range.pop(gn_idx)]\n",
    "            else:\n",
    "                gn_idx = np.random.randint(low=0, high=len(given_names))\n",
    "                gn_pair = given_names[gn_idx]\n",
    "                \n",
    "            gn_pairs.append(gn_pair)\n",
    "\n",
    "        fn_idx = 0\n",
    "        if len(family_names_range) > 0:\n",
    "            fn_idx = np.random.randint(low=0, high=len(family_names_range))\n",
    "            fn_pair = family_names[family_names_range.pop(fn_idx)]\n",
    "        else:\n",
    "            fn_idx = np.random.randint(low=0, high=len(family_names)) \n",
    "            fn_pair = family_names[fn_idx]\n",
    "        \n",
    "\n",
    "        f.write(\"{eg1} {eg2} {eg3} {ef} \\t {ag1} {ag2} {ag3} {af} \\t {pf}\\n\".format(\n",
    "            eg1=gn_pairs[0][0],\n",
    "            eg2=gn_pairs[1][0],\n",
    "            eg3=gn_pairs[2][0],\n",
    "            ef=fn_pair[0],\n",
    "            ag1=gn_pairs[0][1],\n",
    "            ag2=gn_pairs[1][1],\n",
    "            ag3=gn_pairs[2][1],\n",
    "            af=fn_pair[1],\n",
    "            pf=1\n",
    "        ))\n",
    "        \n",
    "        gn_pairs = []\n",
    "        \n",
    "        for i in range(3):\n",
    "            gn_idx = 0\n",
    "            if len(negative_given_names_range) > 0:\n",
    "                gn_idx = np.random.randint(low=0, high=len(negative_given_names_range))\n",
    "                gn_pair = negative_pairs[negative_given_names_range.pop(gn_idx)]\n",
    "            else:\n",
    "                gn_idx = np.random.randint(low=0, high=len(negative_pairs))\n",
    "                gn_pair = negative_pairs[gn_idx]\n",
    "                \n",
    "            gn_pairs.append(gn_pair)\n",
    "\n",
    "        fn_idx = 0\n",
    "        if len(negative_family_names_range) > 0:\n",
    "            fn_idx = np.random.randint(low=0, high=len(negative_family_names_range))\n",
    "            fn_pair = family_negative_pairs[negative_family_names_range.pop(fn_idx)]\n",
    "        else:\n",
    "            fn_idx = np.random.randint(low=0, high=len(family_negative_pairs)) \n",
    "            fn_pair = family_negative_pairs[fn_idx]\n",
    "        \n",
    "        try:\n",
    "            f.write(\"{neg1} {neg2} {neg3} {nef} \\t {nag1} {nag2} {nag3} {naf} \\t {pf}\\n\".format(\n",
    "                neg1=gn_pairs[0][0],\n",
    "                neg2=gn_pairs[1][0],\n",
    "                neg3=gn_pairs[2][0],\n",
    "                nef=fn_pair[0],\n",
    "                nag1=gn_pairs[0][1],\n",
    "                nag2=gn_pairs[1][1],\n",
    "                nag3=gn_pairs[2][1],\n",
    "                naf=fn_pair[1],\n",
    "                pf=0\n",
    "            ))\n",
    "        except:\n",
    "            print(\"gn_pairs : {gn}\".format(gn=gn_pairs))\n",
    "            print(\"fn_pair  : {fn}\".format(fn=fn_pairs))\n",
    "            e = sys.exc_info()[0]\n",
    "            write_to_page( \"<p>Error: %s</p>\" % e )\n",
    "            \n",
    "            \n",
    "        if (len(given_names_range) == 0 and len(family_names_range) == 0) or (len(negative_given_names_range) == 0 and len(negative_family_names_range) == 0):\n",
    "            break\n",
    "          \n",
    "    print(outer_index)\n",
    "    # generate arabic pairs\n",
    "    \n",
    "    \n",
    "    # generate english pairs\n",
    "    \n",
    "    # generate single name values\n",
    "    \n",
    "    \n",
    "    # generate revesed names\n",
    "    \n",
    "    ## \n",
    "    \n",
    "    ## generate negative values\n",
    "    \n",
    "\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "generate_full_names(\"full_names_{gl}_{fl}_negative.tsv\".format(gl=given_limit, fl=family_limit))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BEN MOHAMED', 'BIN MD', 'BIN MOHAMED', 'BIN MOHD', \"M'HAMAD\", \"M'HAMED\", \"M'HAMMAD\", \"M'HAMMED\", \"M'HEMAD\", \"M'HEMED\", \"M'HEMMED\", 'MAHAMAD', 'MAHAMMAD', 'MEHMED', 'MEHMET', 'MHAMAD', 'MHAMED', 'MHAMMAD', 'MHAMMED', 'MHEMAD', 'MHEMED', 'MHEMMED', 'MIHAMAD', 'MIHAMMAD', 'MOCHAMAD', 'MOCHAMAT', 'MOCHAMED', 'MOCHAMET', 'MOCHAMMAD', 'MOCHAMMED', 'MOCHEMAD', 'MOHAMAD', 'MOHAMAT', 'MOHAMD', 'MOHAMED', 'MOHAMEED', 'MOHAMEET', 'MOHAMET', 'MOHAMID', 'MOHAMMAD', 'MOHAMMAT', 'MOHAMMD', 'MOHAMMED', 'MOHAMMEDOLA', 'MOHAMMEED', 'MOHAMMET', 'MOHAMMID', 'MOHAMMIT', 'MOHAMMOD', 'MOHAMMUD', 'MOHAMOOD', 'MOHAMOUD', 'MOHAMUD', 'MOHD', 'MOHEMAD', 'MOHEMAT', 'MOHEMED', 'MOHEMET', 'MOHEMMAD', 'MOHEMMED', 'MOHMD', 'MOHMED', 'MOHMMED', 'MOKHAMAD', 'MOKHAMED', 'MOKHAMMAD', 'MOKHAMMED', 'MOOHAMAD', 'MOOHAMED', 'MOOHAMET', 'MOOHAMID', 'MOOHAMMAD', 'MOOHAMMED', 'MOOHED', 'MOUHAMAD', 'MOUHAMAT', 'MOUHAMED', 'MOUHAMET', 'MOUHAMMAD', 'MOUHAMMED', 'MOUHEMAD', 'MOUHEMED', 'MOUKHAMED', 'MOWHAMMAD', 'MUCHAMAD', 'MUCHAMAT', 'MUCHAMED', 'MUCHAMMAD', 'MUCHAMMED', 'MUHAMAD', 'MUHAMAT', 'MUHAMED', 'MUHAMEED', 'MUHAMEET', 'MUHAMET', 'MUHAMID', 'MUHAMIT', 'MUHAMMAD', 'MUHAMMAT', 'MUHAMMD', 'MUHAMMED', 'MUHAMMEED', 'MUHAMMET', 'MUHAMMID', 'MUHAMMUD', 'MUHAMUD', 'MUHD', 'MUHEMAD', 'MUHEMED', 'MUHEMMAD', 'MUHEMMED', 'MUHEMMET', 'MUHMMAD', 'MUHMMED', 'MUKHAMAD', 'MUKHAMAT', 'MUKHAMED', 'MUKHAMET', 'MUKHAMMAD', 'MUKHAMMAT', 'MUKHAMMED', 'MUKHAMMET', 'MWAHAMD']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(process_name_pair('MOHAMMED', 'محمد', ['given', 'dan'])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('FATIMA', 'فاطمه', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('HAMZA', 'حمزه', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('KAMAL', 'كمال', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('KHALED', 'خالد', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ALI', 'علي', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SALEH', 'صالح', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('IBRAHIM', 'ابرهيم', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('MARIAM', 'مريم', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('HASSAN', 'حسن', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('OMAR', 'عمر', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('HUSSEIN', 'حسين', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SALIM', 'سليم', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SAEED', 'سعيد', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ABBAS', 'عباس', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SAAD', 'سعد', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ELIAS', 'الياس', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('FAISAL', 'فيصل', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('FATIMA', 'فاطمه', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('NASSER', 'ناصر', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ADEL', 'عادل', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('MAHMOUD', 'محمود', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ADNAN', 'عدنان', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SALAH', 'صلاح', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SULTAN', 'سلطان', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SALEM', 'سالم', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('MARIE', 'ماري', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('MOHAMMAD', 'موهاماد', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('DANIEL', 'دانيل', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('JEAN', 'جين', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('YOUSSEF', 'يوسف', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('NASIM', 'نسيم', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ZEYNEP',\n",
       "  'ZENAB',\n",
       "  'ZEINEP',\n",
       "  'ZAINABU',\n",
       "  'ZINAB',\n",
       "  'ZAENAB',\n",
       "  'ZAINAB',\n",
       "  'ZAINEB',\n",
       "  'ZAINUB',\n",
       "  'ZEINEB',\n",
       "  'ZEYNAB',\n",
       "  'ZAYNAB',\n",
       "  'ZAINABA',\n",
       "  'ZAINABAH',\n",
       "  'ZEYNEB',\n",
       "  'ZINEB',\n",
       "  'ZAINABI',\n",
       "  'ZEINAB'],\n",
       " ['زينبذ', 'زناب', 'زينبه', 'زينب ', 'زينب'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_name_pair('ZAINAB', 'زينب', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('NOUR', 'نور', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('MALEK', 'مالك', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('MOSTAFA', 'مصطفى', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('AMMAR', 'عمار', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('DAVID', 'دافيد', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ABDUL', 'عبدول', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('HAMED', 'حامد', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['JOSEPH', 'JOZEF', 'JOSEF', 'GOOZF', 'JOZSEF', 'JOSEPH MC'],\n",
       " ['جوزيف', 'جوزيف مك', 'جوزسف', 'جوسف', 'جوزف'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_name_pair('JOSEPH', 'جوزيف', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('GEORGE', 'جورج', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('FOUAD', 'فؤاد', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('FATIMA', 'فطيمه', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('LAILA', 'ليلى', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['CHARLES'], ['تشارلس'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_name_pair('CHARLES', 'تشارلس', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('CASE', 'قاسى', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SAYED',\n",
       "  'SAYAD',\n",
       "  'SAIDU',\n",
       "  'SAIDI',\n",
       "  'SAEEDA',\n",
       "  'SAID EL',\n",
       "  'SAYID',\n",
       "  'SAEID',\n",
       "  'SAEED',\n",
       "  'SEIDA',\n",
       "  'SAID',\n",
       "  'SAIED',\n",
       "  'SAIDA',\n",
       "  'SAEEDAH'],\n",
       " ['سعيده', 'سايد', 'سعيد', 'سائد'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_name_pair(\"SAEED\", 'سعيد', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair(\"MICHA'EL\", 'ميخائيل', [ 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' AISHA',\n",
       "  'AICHA',\n",
       "  'AISHA',\n",
       "  'AAISHA',\n",
       "  'AYSHA',\n",
       "  'AESHA',\n",
       "  'AAESHA',\n",
       "  'EESHA',\n",
       "  'AAYISHA',\n",
       "  'AYESHA',\n",
       "  'EISHA',\n",
       "  'ESHA',\n",
       "  'AAYESHEH',\n",
       "  'JAGADEESHA',\n",
       "  'AYISHA',\n",
       "  'AEESHA',\n",
       "  'AIESHA',\n",
       "  'AAYSHA',\n",
       "  'AAYESHA',\n",
       "  'ASHA'],\n",
       " ['عائيشه',\n",
       "  'عائشه ',\n",
       "  'عشا',\n",
       "  'عيشه',\n",
       "  'أيتشا',\n",
       "  'عائشه',\n",
       "  'عايشة',\n",
       "  'عئشه',\n",
       "  'عايشه',\n",
       "  'عيشة'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_name_pair('AAESHA', 'عائشه', ['given', 'dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('JACOB', 'جاكوب', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('REZA', 'رضا', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('GABRIEL', 'جبريل', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ALEXANDER', 'الكسندر', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SMITH', 'سميث', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('RAHIM', 'رحيم', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('KUMAR', 'كمار', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('FRANCIS', 'فرانسيس', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('NGUYEN', 'نجاين', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ROBERT', 'روبرت', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SHAIKH', 'شيخ', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('JAMAL', 'جمال', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('PETERS', 'بطرس', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ISLAM', 'اسلام', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('JAMES', 'جيمس', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('CHAN', 'تشان', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('JACOB', 'جاكوب', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('KABIR', 'كعبر', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['RICHARD'], ['ريشارد'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_name_pair('RICHARD', 'ريشارد', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('IDRIS', 'ادريس', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['REHMAN', 'REHIMAN', 'REHAMAN', 'RAHMAN', 'RHAMAN', 'REHUMAN'],\n",
       " ['رحمان', 'رحمن'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_name_pair('REHMAN', 'رحمن', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('PEREIRA', 'بريرا', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ZAFAR', 'ظافر', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('ISHAK', 'اسحاق', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('CHRISTIAN', 'كريستيان', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('SAMUEL', 'صامويل', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_name_pair('USMAN', 'عثمان', ['given', 'dan', 'family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
