{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# database related code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from configparser import ConfigParser\n",
    "\n",
    "def config(filename='prepare_data.ini', section='phonetic'):\n",
    "    # create a parser\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(filename)\n",
    " \n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    " \n",
    "    return db\n",
    "\n",
    "def db_connect():\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    # read connection parameters\n",
    "    params = config()\n",
    "\n",
    "    # connect to the PostgreSQL server\n",
    "    conn = psycopg2.connect(**params)\n",
    "    print('Connected to the PostgreSQL database...')\n",
    "    \n",
    "    return conn\n",
    "\n",
    "def read_dataframe():\n",
    "    conn = db_connect()\n",
    "    result = None\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT * FROM GIVEN_NAMES_MASTER\n",
    "            WHERE ARB IS NOT NULL AND ENG IS NOT NULL AND ARB != '' AND ENG != ''\n",
    "            UNION ALL SELECT * FROM FAMILY_NAMES_MASTER\n",
    "            WHERE ARB IS NOT NULL AND ENG IS NOT NULL AND ARB != '' AND ENG != ''\n",
    "            UNION ALL SELECT * FROM GIVEN_NAMES_DAN\n",
    "            WHERE ARB IS NOT NULL AND ENG IS NOT NULL AND ARB != '' AND ENG != ''\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "        result = pd.read_sql(query, con=conn, index_col='id')\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "            \n",
    "    print(\"data retrieved from database with size: {size}\".format(size= result.shape))\n",
    "    return result\n",
    "\n",
    "def read_eng_given_names():\n",
    "    conn = db_connect()\n",
    "    result = None\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT * FROM (\n",
    "                SELECT NAME, SUM(COUNT) AS S FROM (\n",
    "                    SELECT ENG AS NAME, COUNT FROM GIVEN_NAMES_MASTER\n",
    "                    WHERE ENG IS NOT NULL AND ENG != '' AND ARB IS NOT NULL AND ARB != ''\n",
    "                ) AS SUB GROUP BY NAME\n",
    "                ORDER BY S DESC\n",
    "            ) AS S2 WHERE S >= 10;\n",
    "            \"\"\"\n",
    "        result = pd.read_sql(query, con=conn)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "            \n",
    "    print(\"data retrieved from database with size: {size}\".format(size= result.shape))\n",
    "    return result\n",
    "\n",
    "def read_arb_given_names():\n",
    "    conn = db_connect()\n",
    "    result = None\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT * FROM (\n",
    "                SELECT NAME, SUM(COUNT) as s FROM (\n",
    "                    SELECT ARB AS NAME, COUNT FROM GIVEN_NAMES_MASTER\n",
    "                    WHERE ENG IS NOT NULL AND ENG != '' AND ARB IS NOT NULL AND ARB != ''\n",
    "                ) AS SUB GROUP BY NAME\n",
    "                ORDER BY S DESC\n",
    "            ) AS S2 WHERE S >= 10;\n",
    "            \"\"\"\n",
    "        result = pd.read_sql(query, con=conn)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "            \n",
    "    print(\"data retrieved from database with size: {size}\".format(size= result.shape))\n",
    "    return result\n",
    "\n",
    "def read_eng_family_names():\n",
    "    conn = db_connect()\n",
    "    result = None\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT * FROM (\n",
    "                SELECT NAME, SUM(COUNT) AS S FROM (\n",
    "                    SELECT ENG AS NAME, COUNT FROM FAMILY_NAMES_MASTER\n",
    "                    WHERE ENG IS NOT NULL AND ENG != '' AND ARB IS NOT NULL AND ARB != ''\n",
    "                ) AS SUB GROUP BY NAME\n",
    "                ORDER BY S DESC\n",
    "            ) AS S2 WHERE S >= 10;\n",
    "            \"\"\"\n",
    "        result = pd.read_sql(query, con=conn)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "            \n",
    "    print(\"data retrieved from database with size: {size}\".format(size= result.shape))\n",
    "    return result\n",
    "\n",
    "def read_arb_family_names():\n",
    "    conn = db_connect()\n",
    "    result = None\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT * FROM (\n",
    "                SELECT NAME, SUM(COUNT) AS S FROM (\n",
    "                    SELECT ARB AS NAME, COUNT FROM FAMILY_NAMES_MASTER\n",
    "                    WHERE ENG IS NOT NULL AND ENG != '' AND ARB IS NOT NULL AND ARB != ''\n",
    "                ) AS S1 GROUP BY NAME\n",
    "                ORDER BY S DESC\n",
    "            ) AS S2 WHERE S >= 10;\n",
    "            \"\"\"\n",
    "        result = pd.read_sql(query, con=conn)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "            \n",
    "    print(\"data retrieved from database with size: {size}\".format(size= result.shape))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph related fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def generate_names_graph():\n",
    "    \n",
    "    global df\n",
    "    \n",
    "    if df.empty:\n",
    "        df = read_dataframe()   \n",
    "\n",
    "    global G\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        arb, eng, cnt = row['arb'], row['eng'], row['count']\n",
    "        if G.has_edge(arb, eng):\n",
    "                    G[arb][eng]['weight'] += cnt\n",
    "        else:\n",
    "            G.add_edge(arb, eng, weight=cnt)\n",
    "\n",
    "    nx.write_gpickle(G,\"/home/jupyter/notebooks/PoC/data-preparation/pickle/names_graph.gpickle\")\n",
    "    \n",
    "def read_pickled_names_graph():\n",
    "    global G\n",
    "    G = nx.read_gpickle(\"/home/jupyter/notebooks/PoC/data-preparation/pickle/names_graph.gpickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resetting dataframe, execute only if you need to get all data from db again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "eng_gnames = pd.DataFrame()\n",
    "eng_fnames = pd.DataFrame()\n",
    "arb_gnames = pd.DataFrame()\n",
    "arb_fnames = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_total_result = []\n",
    "arabic_total_result = []\n",
    "top_noise_data = []\n",
    "origin_name = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get variations functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_english_variantions(validate = False): \n",
    "    global arabic_total_result, english_total_result\n",
    "    iterable_list = arabic_total_result[:]\n",
    "    for arabic_name in iterable_list:\n",
    "        english_list = get_english_variants(arabic_name)\n",
    "        english_total_result += get_top_frequency_names(english_list)\n",
    "    english_total_result = list(set(english_total_result))\n",
    "    \n",
    "    if validate:\n",
    "        iterable_list = english_total_result[:]\n",
    "        for english_name in iterable_list:\n",
    "            if not validate_english_name_by_arabic_variations(english_name, arabic_total_result):\n",
    "                print(\"removing name: {name}\".format(name=english_name))\n",
    "                english_total_result.remove(english_name)\n",
    "        english_total_result.sort()\n",
    "        \n",
    "                \n",
    "def get_arabic_variantions(validate = False): \n",
    "    global arabic_total_result, english_total_result\n",
    "    iterable_list = english_total_result[:]\n",
    "    for english_name in iterable_list:\n",
    "        arabic_list = get_arabic_variants(english_name)\n",
    "        arabic_total_result += get_top_frequency_names(arabic_list)\n",
    "    arabic_total_result = list(set(arabic_total_result))\n",
    "\n",
    "    if validate:\n",
    "        iterable_list = arabic_total_result[:]\n",
    "        for arabic_name in iterable_list:\n",
    "            if not validate_arabic_name_by_english_variations(arabic_name, english_total_result):\n",
    "                print(\"removing name: {name}\".format(name=arabic_name))\n",
    "                arabic_total_result.remove(arabic_name)\n",
    "\n",
    "        arabic_total_result.sort()\n",
    "             \n",
    "\"\"\"\n",
    "def get_english_variants(arabic_name):\n",
    "    global df\n",
    "    \n",
    "    if df.empty:\n",
    "        df = read_dataframe()   \n",
    "    \n",
    "    result = {}\n",
    "    a = df[df['arb'] == arabic_name]\n",
    "    b = a[['eng', 'count']].groupby('eng').sum()\n",
    "    result = b.to_dict()['count']\n",
    "    return result\n",
    "\n",
    "def get_arabic_variants(english_name): \n",
    "    global df\n",
    "    \n",
    "    if df.empty:\n",
    "        df = read_dataframe()\n",
    "    \n",
    "    result = {}\n",
    "    a = df[df['eng'] == english_name]\n",
    "    b = a[['arb', 'count']].groupby('arb').sum()\n",
    "    result = b.to_dict()['count']\n",
    "    \n",
    "    return result\n",
    "\"\"\"\n",
    "\n",
    "def get_english_variants(name):\n",
    "    \n",
    "    result = {}\n",
    "    for v,u in nx.edges(G, name):\n",
    "        result[u] = G[v][u]['weight']\n",
    "    return result\n",
    "\n",
    "def get_arabic_variants(name): \n",
    "     \n",
    "    result = {}\n",
    "    for v,u in nx.edges(G, name):\n",
    "        result[u] = G[v][u]['weight']\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def validate_arabic_name_by_english_variations(arabic_name, valid_english_variations):\n",
    "    english_variations = get_english_variants(arabic_name)\n",
    "    total_valid_count = 0\n",
    "    total_invalid_count = 0\n",
    "    \n",
    "    total = sum(english_variations.values())\n",
    "    if total < 3:\n",
    "        return False\n",
    "\n",
    "    for key, val in english_variations.items():\n",
    "        if key in valid_english_variations:\n",
    "            total_valid_count += val\n",
    "        else:\n",
    "            total_invalid_count += val\n",
    "    \n",
    "    #print(\"for {name}: valid: {valid}, invalid: {invalid}\".format(name=arabic_name, valid=total_valid_count, invalid=total_invalid_count))\n",
    "    \n",
    "    if total_valid_count < 3:\n",
    "        return False\n",
    "\n",
    "    if total_valid_count > total_invalid_count or total_valid_count > 100:\n",
    "        return True\n",
    "    \n",
    "    #print(\"english variations for {name} are: {dic}\".format(name=arabic_name, dic=english_variations))\n",
    "    return False\n",
    "    \n",
    "def validate_english_name_by_arabic_variations(english_name, valid_arabic_variations):\n",
    "    arabic_variations = get_arabic_variants(english_name)\n",
    "    total_valid_count = 0\n",
    "    total_invalid_count = 0\n",
    "    \n",
    "    total = sum(arabic_variations.values())\n",
    "    if total < 3:\n",
    "        return False\n",
    "    \n",
    "    for key, val in arabic_variations.items():\n",
    "        if key in valid_arabic_variations:\n",
    "            total_valid_count += val\n",
    "        else:\n",
    "            total_invalid_count += val\n",
    "    \n",
    "    #print(\"for {name}: valid: {valid}, invalid: {invalid}\".format(name=arabic_name, valid=total_valid_count, invalid=total_invalid_count))\n",
    "\n",
    "    if total_valid_count < 3:\n",
    "        return False\n",
    "    \n",
    "    if total_valid_count > total_invalid_count or total_valid_count > 100:\n",
    "        return True\n",
    "    \n",
    "    #print(\"arabic variations for {name} are: {dic}\".format(name=english_name, dic=arabic_variations))\n",
    "    return False\n",
    "\n",
    "def get_top_frequency_names(list):\n",
    "    total = sum(list.values())\n",
    "    lower_accepted_frequency = 100\n",
    "    threshold = 10\n",
    "    \n",
    "    max_value = max(list.values())\n",
    "    if total > 6561:\n",
    "        threshold = 1\n",
    "    else:\n",
    "        threshold -= total**(1./4.)\n",
    "        \n",
    "    #print(\"threshold: {thre}, total: {tot}\".format(thre=threshold, tot=total))\n",
    "    matched_list = [key for key, val in list.items() \n",
    "                    if len(key) > 2 and \n",
    "                    key not in top_noise_data and \n",
    "                    (val / total * 100 > threshold or val >= lower_accepted_frequency)]\n",
    "    #print(\"top matched_list: {thre}\".format(thre=matched_list))\n",
    "    not_matched_list = [ (key, val) for key, val in list.items() if val / total * 100 <= threshold and val < lower_accepted_frequency]\n",
    "    matched_list_with_composite = [key for key, val in list.items() \n",
    "                                   if any(match in key and len(key) < len(match) * 2  for match in matched_list)]\n",
    "    if(len(matched_list_with_composite) - len(matched_list) > 3):\n",
    "        return matched_list\n",
    "    \n",
    "    return matched_list_with_composite\n",
    "\n",
    "def get_random_names(names, number=20):\n",
    "    rnd = []\n",
    "    rnd.extend(np.random.randint(low=0, high=int(np.floor(len(names) * 0.01)), size=int(np.ceil(number * 0.5))))\n",
    "    rnd.extend(np.random.randint(low=int(np.floor(len(names) * 0.01)+1), high=int(np.floor(len(names) * 0.5)), size=int(np.ceil(number * 0.3))))\n",
    "    rnd.extend(np.random.randint(low=int(np.floor(len(names) * 0.5)+1), high=len(names), size=int(np.ceil(number * 0.2))))\n",
    "    return [names.loc[rnd[num],'name'] for num in range(number)]\n",
    "    \n",
    "def rnd_english_given_names(number=20):\n",
    "    global eng_gnames\n",
    "    \n",
    "    if eng_gnames.empty:\n",
    "        eng_gnames = read_eng_given_names()\n",
    "\n",
    "    return get_random_names(eng_gnames, number)\n",
    "\n",
    "def rnd_arabic_given_names(number=20):\n",
    "    global arb_gnames\n",
    "    \n",
    "    if arb_gnames.empty:\n",
    "        arb_gnames = read_arb_given_names()\n",
    "\n",
    "    return get_random_names(arb_gnames, number)\n",
    "\n",
    "def rnd_english_family_names(number=20):\n",
    "    global eng_fnames\n",
    "    \n",
    "    if eng_fnames.empty:\n",
    "        eng_fnames = read_eng_family_names()\n",
    "\n",
    "    return get_random_names(eng_fnames, number)\n",
    "\n",
    "def rnd_arabic_family_names(number=20):\n",
    "    global arb_fnames\n",
    "    \n",
    "    if arb_fnames.empty:\n",
    "        arb_fnames = read_arb_family_names()\n",
    "\n",
    "    return get_random_names(arb_fnames, number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_global_variables(name):\n",
    "    global english_total_result, arabic_total_result, top_noise_data, origin_name\n",
    "    english_total_result = []\n",
    "    arabic_total_result = []\n",
    "    top_noise_data = ['MRS', 'MRS.', 'MRSS', 'MR', 'MR.', 'MISS']\n",
    "    origin_name = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load initial arabic variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top arabic results: ['موهامد', 'محمد']\n"
     ]
    }
   ],
   "source": [
    "read_pickled_names_graph()\n",
    "reset_global_variables('MOHAMED')\n",
    "english_total_result.append(origin_name)\n",
    "get_arabic_variantions()\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get initial english variations list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top english results: ['MOHAMID', 'MOUKHAMED', 'MHEMMED', 'MEHAMED', 'MUHAMMET', 'MUHEMED', 'MOCHAMAD', 'MIHAMAD', 'MOOHAMID', 'MOKHAMED', 'MUKHAMMAT', 'MOHAMAT', 'MOHAMEED', 'MUHAMIT', 'MUHAMMAD', 'MUKHAMMET', 'MOUHAMMED', 'MUCHAMMED', 'MWAHAMD', 'MOOHAMED', 'MOHAMMUD', 'MOUHAMAD', 'MEHAMMED', \"M'HAMMED\", 'MUHMMED', 'MOHAMMED', 'MUHAMEED', 'MOUHEMAD', 'MUHAMAT', 'MUHAMMAT', 'MOCHAMED', 'MOKHAMMED', 'MUHEMMAD', 'MOHAMMAT', 'MOCHAMMED', 'MHEMAD', 'MUHAMMID', 'MOHAMD', 'MOUHAMAT', \"M'HEMMED\", 'MHEMED', 'MUHAMMEED', 'MUKHAMMAD', 'MOHAMMID', 'MOHEMAT', 'MUHMMAD', 'MOOHAMMAD', 'MOCHEMAD', 'MOCHAMET', 'MOKHAMAD', 'MUHAMEET', 'MAHAMAD', 'MHAMMAD', \"M'HEMED\", \"M'HAMAD\", 'MUHAMMUD', 'MUHAMID', 'MOUHEMED', 'MUKHAMAT', 'MUKHAMMED', 'MUCHAMAD', 'MIHAMMAD', 'MOUHAMMAD', 'MUHD', 'MUKHAMED', 'MOUHAMED', 'MOHAMMEED', 'MOKHAMMAD', 'MOHAMMD', 'MOHEMMAD', 'MOHMED', 'MHAMED', 'MOHAMEET', 'MOOHAMAD', 'MUHEMMED', 'MUHAMET', 'MUHAMED', 'MOHAMED', 'MOHAMAD', 'MUKHAMET', 'MUHAMAD', 'MOHAMUD', 'MOWHAMMAD', 'MOOHAMET', 'MOHEMED', 'MUHEMMET', 'MOCHAMAT', 'MOOHAMMED', 'MHAMAD', \"M'HAMMAD\", \"M'HAMED\", 'MUCHAMAT', 'MOHAMMAD', 'MHAMMED', 'MUCHAMED', 'MOCHAMMAD', 'MOHEMAD', 'MOHD', 'MUHAMMED', 'MUHEMAD', 'MOHAMMET', 'MOHAMMIT', 'MUHAMUD', 'MOUHAMET', 'MEHMET', 'MOHEMET', 'MEHMED', 'MUHAMMD', 'MUKHAMAD', \"M'HEMAD\", 'MOHEMMED', 'MUCHAMMAD', 'MOHAMET', 'MAHAMMAD']\n"
     ]
    }
   ],
   "source": [
    "get_english_variantions()\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get more variations and validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing name: محمدنيل\n",
      "removing name: بن محمد\n",
      "removing name: محمدعلى\n",
      "removing name: امحمد\n",
      "removing name: محمدنور\n",
      "removing name: محمد \n",
      "top arabic results: ['ماهاماد', 'محماد', 'محمد', 'محمّد', 'مخمد', 'مهمت', 'موتشاماد', 'موحد', 'موهامات', 'موهاماد', 'موهامت', 'موهامد', 'موهامود', 'موهاميد', 'موهمد']\n"
     ]
    }
   ],
   "source": [
    "get_arabic_variantions(True)\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top english results: [\"M'HAMAD\", \"M'HAMED\", \"M'HAMMAD\", \"M'HAMMED\", \"M'HEMAD\", \"M'HEMED\", \"M'HEMMED\", 'MAHAMAD', 'MAHAMMAD', 'MEHAMED', 'MEHAMMED', 'MEHMED', 'MEHMET', 'MHAMAD', 'MHAMED', 'MHAMMAD', 'MHAMMED', 'MHEMAD', 'MHEMED', 'MHEMMED', 'MIHAMAD', 'MIHAMMAD', 'MOCHAMAD', 'MOCHAMAT', 'MOCHAMED', 'MOCHAMET', 'MOCHAMMAD', 'MOCHAMMED', 'MOCHEMAD', 'MOHAMAD', 'MOHAMADE', 'MOHAMAT', 'MOHAMD', 'MOHAMED', 'MOHAMEED', 'MOHAMEET', 'MOHAMET', 'MOHAMID', 'MOHAMMAD', 'MOHAMMAT', 'MOHAMMD', 'MOHAMMED', 'MOHAMMEED', 'MOHAMMET', 'MOHAMMID', 'MOHAMMIT', 'MOHAMMOD', 'MOHAMMUD', 'MOHAMOOD', 'MOHAMOUD', 'MOHAMUD', 'MOHD', 'MOHEMAD', 'MOHEMAT', 'MOHEMED', 'MOHEMET', 'MOHEMMAD', 'MOHEMMED', 'MOHMD', 'MOHMED', 'MOHMMED', 'MOKHAMAD', 'MOKHAMED', 'MOKHAMMAD', 'MOKHAMMED', 'MOOHAMAD', 'MOOHAMED', 'MOOHAMET', 'MOOHAMID', 'MOOHAMMAD', 'MOOHAMMED', 'MOOHED', 'MOUHAMAD', 'MOUHAMAT', 'MOUHAMATT', 'MOUHAMED', 'MOUHAMET', 'MOUHAMMAD', 'MOUHAMMED', 'MOUHEMAD', 'MOUHEMED', 'MOUKHAMED', 'MOWHAMMAD', 'MUCHAMAD', 'MUCHAMAT', 'MUCHAMED', 'MUCHAMMAD', 'MUCHAMMED', 'MUHAMAD', 'MUHAMAT', 'MUHAMED', 'MUHAMEED', 'MUHAMEET', 'MUHAMET', 'MUHAMID', 'MUHAMIT', 'MUHAMMAD', 'MUHAMMAT', 'MUHAMMD', 'MUHAMMED', 'MUHAMMEED', 'MUHAMMET', 'MUHAMMID', 'MUHAMMUD', 'MUHAMUD', 'MUHD', 'MUHEMAD', 'MUHEMED', 'MUHEMMAD', 'MUHEMMED', 'MUHEMMET', 'MUHMMAD', 'MUHMMED', 'MUKHAMAD', 'MUKHAMAT', 'MUKHAMED', 'MUKHAMET', 'MUKHAMMAD', 'MUKHAMMAT', 'MUKHAMMED', 'MUKHAMMET', 'MWAHAMD']\n"
     ]
    }
   ],
   "source": [
    "get_english_variantions(True)\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top arabic results: ['مهير', 'مهر', 'ماهر', 'ماهير']\n",
      "top english results: ['MAHIIR', 'MAAIR', 'MEHR', 'MOUHR', 'MAHEAR', 'MAHIER', 'MEIR', 'MAHRI', 'MAHIRE', 'MAHR', 'MAHHER', 'MER', 'MAIR', 'MAHAR', 'MAYR', 'MEAIR', 'MEHEIR', 'MAHAIR', 'MYHR', 'MUHR', 'MAHER', 'MEEIR', 'MAHIR', 'MIHIR', 'MAIIR', 'MEHEAR', 'MAR', 'MAHERE', 'MAAIER', 'MAHEIR', 'MAEAR', 'MAEIR', 'MHER', 'MAAR', 'MEHIER', 'MEHIR', 'MAAER', 'MEHER', 'MEYR', 'MEHEER', 'MEIIR', 'MAEER', 'MAAHIR', 'MIHR', 'MEER', 'MAER', 'MAAHER', 'MAHAMARAKKALAGE', 'MEEER', 'MEEAR', 'MOOHR', 'MAIER', 'MEHAR', 'MEEHR', 'MOHEER', 'MOHR', 'MEHAIR', 'MAHYR', 'MAHEER', 'MEIER']\n",
      "removing name: مهرى\n",
      "removing name: ماهر ى\n",
      "top arabic results: ['ماهر', 'ماهرة', 'ماهرى', 'ماهير', 'مايار', 'ماير', 'محار', 'مهر', 'مهير', 'مهيرة', 'مير']\n",
      "removing name: MIRR\n",
      "top english results: ['MAAAIRA', 'MAAER', 'MAAHER', 'MAAHIR', 'MAAHIRA', 'MAAHIRAH', 'MAAIER', 'MAAIR', 'MAAIRA', 'MAAR', 'MAAYAR', 'MAAYER', 'MAAYRA', 'MAEAR', 'MAEARA', 'MAEER', 'MAEERA', 'MAEERE', 'MAEIR', 'MAEIRA', 'MAER', 'MAERA', 'MAERAH', 'MAERE', 'MAEYER', 'MAHAIR', 'MAHAIRA', 'MAHAIRE', 'MAHAMARAKKALAGE', 'MAHAR', 'MAHARA', 'MAHEAR', 'MAHEARA', 'MAHEER', 'MAHEERA', 'MAHEIR', 'MAHEIRA', 'MAHER', 'MAHERA', 'MAHERAH', 'MAHERE', 'MAHHER', 'MAHHERE', 'MAHIAR', 'MAHIER', 'MAHIIR', 'MAHIR', 'MAHIRA', 'MAHIRAH', 'MAHIRE', 'MAHR', 'MAHRI', 'MAHYAR', 'MAHYER', 'MAHYR', 'MAHYRA', 'MAIAR', 'MAIER', 'MAIERA', 'MAIERE', 'MAIIR', 'MAIIRA', 'MAIIRE', 'MAIR', 'MAIRA', 'MAIRAH', 'MAIRE', 'MAIREH', 'MAIRI', 'MAR', 'MAYAAR', 'MAYAR', 'MAYARI', 'MAYER', 'MAYERE', 'MAYOR', 'MAYR', 'MAYRA', 'MAYRAH', 'MAYRE', 'MAYREH', 'MAYUR', 'MAYURI', 'MEAIR', 'MEAIRA', 'MEEAR', 'MEEARA', 'MEEARE', 'MEEER', 'MEEERA', 'MEEERE', 'MEEHR', 'MEEIR', 'MEEIRA', 'MEER', 'MEERA', 'MEERAH', 'MEERE', 'MEEREH', 'MEHAIR', 'MEHAIRAH', 'MEHAIRE', 'MEHAR', 'MEHEAR', 'MEHEER', 'MEHEIR', 'MEHEIRA', 'MEHEIRAH', 'MEHER', 'MEHERA', 'MEHERE', 'MEHIER', 'MEHIERE', 'MEHIR', 'MEHIRA', 'MEHIRE', 'MEHR', 'MEIAR', 'MEIER', 'MEIERA', 'MEIERE', 'MEIIR', 'MEIIRA', 'MEIIRE', 'MEIR', 'MEIRA', 'MEIRAH', 'MEIRE', 'MEIREH', 'MER', 'MEYAAR', 'MEYAR', 'MEYER', 'MEYR', 'MEYRA', 'MEYRE', 'MHER', 'MIERE', 'MIHIR', 'MIHR', 'MIR', 'MOAYERI', 'MOHAIRA', 'MOHAIRE', 'MOHEER', 'MOHIRA', 'MOHIRE', 'MOHR', 'MOOHR', 'MOUHR', 'MUHAIRA', 'MUHIRA', 'MUHIRE', 'MUHR', 'MYHR', 'MYR']\n"
     ]
    }
   ],
   "source": [
    "reset_global_variables('MAHIR')\n",
    "english_total_result.append(origin_name)\n",
    "get_arabic_variantions()\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions()\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))\n",
    "get_arabic_variantions(True)\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions(True)\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top arabic results: ['حمزة', 'حمزه']\n",
      "top english results: ['HUMZA', 'HAMZA', 'HAMZAH', 'KHAMZA']\n",
      "top arabic results: ['حمزة', 'حمزه', 'هامزه']\n",
      "top english results: ['HAMZA', 'HAMZAH', 'HAMZEH', 'HUMZA', 'KHAMZA']\n"
     ]
    }
   ],
   "source": [
    "reset_global_variables('HAMZA')\n",
    "english_total_result.append(origin_name)\n",
    "get_arabic_variantions()\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions()\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))\n",
    "get_arabic_variantions(True)\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions(True)\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_global_variables('MARY')\n",
    "english_total_result.append(origin_name)\n",
    "get_arabic_variantions()\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions()\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))\n",
    "get_arabic_variantions(True)\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions(True)\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_iteration_english = (df['eng'] == 'MICHAEL')\n",
    "first_iteration_arabic = (df['arb'].isin(df[first_iteration_english]['arb']))\n",
    "second_iteration_english = (df['eng'].isin(df[first_iteration_arabic]['eng']))\n",
    "second_iteration_arabic = (df['arb'].isin(df[second_iteration_english]['arb']))\n",
    "df[first_iteration_english | first_iteration_arabic | second_iteration_english | second_iteration_arabic]\n",
    "\n",
    "#df[df['eng'] == 'MICHAEL']\n",
    "#df[df['eng'] == 'MICHAEL' | df['arb'] in df[df['eng'] == 'MICHAEL']['arb']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_global_variables('MICHAEL')\n",
    "english_total_result.append(origin_name)\n",
    "get_arabic_variantions()\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions()\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))\n",
    "get_arabic_variantions(True)\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions(True)\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reset_global_variables('OMAR')\n",
    "english_total_result.append(origin_name)\n",
    "get_arabic_variantions()\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions()\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))\n",
    "get_arabic_variantions(True)\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions(True)\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reset_global_variables('AMMAR')\n",
    "english_total_result.append(origin_name)\n",
    "get_arabic_variantions()\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions()\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))\n",
    "get_arabic_variantions(True)\n",
    "print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "get_english_variantions(True)\n",
    "print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "read_pickled_names_graph()\n",
    "names = rnd_english_given_names(99)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "names = ['MOHAMED', 'ANTON', 'SHAMA', 'OBAID', 'SMIRA', 'SAFA', 'AHMED', 'RASHEED', 'FIRST NAME', 'SAYED', 'JEAN', 'THAMER', 'ZIAD', 'NADER', 'SHAHD', 'AFRAH', 'AZZA', 'ALAA', 'SHEHAB', 'WAGDA', 'GHAREEB', 'POST GRAND NAME', 'DALAL', 'FARES', 'ADNAN', 'YASIN', 'SAFAA', 'IHAB', 'BASMA', 'RASHID', 'HODA', 'HELAL', 'LINA', 'LAURA', 'QASEM', 'DALAL', 'EMAD', 'HAMAD', 'YASIN', 'OSAMA', 'WESAM', 'AFAF', 'IVAN', 'EMMANUEL', 'MICHAEL', 'SEBASTIAN', 'JOSEPH', 'HANEEN', 'SOHAIL', 'ADAM', 'AMMAR', 'KERYN', 'MIIKA', 'TRIPTI', 'PALANIAPPAN', 'JANNE', 'CHATHURA', 'BHUWAN', 'CARLY', 'JAYANTI', 'JADHAV', 'LENIN', 'JOSY', 'HAKIMULLAH', 'BURTON', 'ILONA', 'AAFIYA', 'SUBAIDHA', 'ANGELIQUE', 'SHOHID', 'ALBERTINA', 'MALHAR', 'POOJA', 'MEG', 'GOMATHI', 'SHAKEER', 'DARPAN', 'BHURA', 'ANNELIZE', 'DEVENDRAN', 'JINDER', 'METILDA', 'BIRATI', 'IMPERIAL', 'OTTONIEL', 'LASANTHI', 'YANDIR', 'SAHIT', 'SANTILLAN', 'WASRIAH', 'MUSLIHAH', 'MAHINDERPERSAD', 'CAR NI', 'NAZRI BIN', 'THULANI', 'ALIMAH', 'ABDULLAYEVA', 'NOIME', 'AKHMETOV', 'GENARD']\n",
    "for name in names:\n",
    "    reset_global_variables(name)\n",
    "    english_total_result.append(origin_name)\n",
    "    get_arabic_variantions()\n",
    "    get_english_variantions()\n",
    "    get_arabic_variantions(True)\n",
    "    print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "    get_english_variantions(True)\n",
    "    print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "names = ['MOHAMED', 'ANTON', 'SHAMA', 'OBAID', 'SMIRA', 'SAFA', 'AHMED', 'RASHEED', 'FIRST NAME', 'SAYED', 'JEAN', 'THAMER', 'ZIAD', 'NADER', 'SHAHD', 'AFRAH', 'AZZA', 'ALAA', 'SHEHAB', 'WAGDA', 'GHAREEB', 'POST GRAND NAME', 'DALAL', 'FARES', 'ADNAN', 'YASIN', 'SAFAA', 'IHAB', 'BASMA', 'RASHID', 'HODA', 'HELAL', 'LINA', 'LAURA', 'QASEM', 'DALAL', 'EMAD', 'HAMAD', 'YASIN', 'OSAMA', 'WESAM', 'AFAF', 'IVAN', 'EMMANUEL', 'MICHAEL', 'SEBASTIAN', 'JOSEPH', 'HANEEN', 'SOHAIL', 'ADAM', 'AMMAR', 'KERYN', 'MIIKA', 'TRIPTI', 'PALANIAPPAN', 'JANNE', 'CHATHURA', 'BHUWAN', 'CARLY', 'JAYANTI', 'JADHAV', 'LENIN', 'JOSY', 'HAKIMULLAH', 'BURTON', 'ILONA', 'AAFIYA', 'SUBAIDHA', 'ANGELIQUE', 'SHOHID', 'ALBERTINA', 'MALHAR', 'POOJA', 'MEG', 'GOMATHI', 'SHAKEER', 'DARPAN', 'BHURA', 'ANNELIZE', 'DEVENDRAN', 'JINDER', 'METILDA', 'BIRATI', 'IMPERIAL', 'OTTONIEL', 'LASANTHI', 'YANDIR', 'SAHIT', 'SANTILLAN', 'WASRIAH', 'MUSLIHAH', 'MAHINDERPERSAD', 'CAR NI', 'NAZRI BIN', 'THULANI', 'ALIMAH', 'ABDULLAYEVA', 'NOIME', 'AKHMETOV', 'GENARD']\n",
    "for name in names:\n",
    "    reset_global_variables(name)\n",
    "    english_total_result.append(origin_name)\n",
    "    get_arabic_variantions()\n",
    "    get_english_variantions()\n",
    "    get_arabic_variantions(True)\n",
    "    print(\"top arabic results: {dct}\".format(dct=arabic_total_result))\n",
    "    get_english_variantions(True)\n",
    "    print(\"top english results: {dct}\".format(dct=english_total_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
